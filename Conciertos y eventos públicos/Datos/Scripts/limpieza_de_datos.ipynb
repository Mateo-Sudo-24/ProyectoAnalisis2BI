{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50824e1-bae3-45b7-a0f7-0035b2e50165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating       timestamp  \\\n",
      "0       1        2     3.5  2/4/2005 23:53   \n",
      "1       1       29     3.5  2/4/2005 23:31   \n",
      "2       1       32     3.5  2/4/2005 23:33   \n",
      "3       1       47     3.5  2/4/2005 23:32   \n",
      "4       1       50     3.5  2/4/2005 23:29   \n",
      "\n",
      "                                               title  \\\n",
      "0                                     Jumanji (1995)   \n",
      "1  City of Lost Children, The (Cité des enfants p...   \n",
      "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
      "3                        Seven (a.k.a. Se7en) (1995)   \n",
      "4                         Usual Suspects, The (1995)   \n",
      "\n",
      "                                   genres  \n",
      "0              Adventure|Children|Fantasy  \n",
      "1  Adventure|Drama|Fantasy|Mystery|Sci-Fi  \n",
      "2                 Mystery|Sci-Fi|Thriller  \n",
      "3                        Mystery|Thriller  \n",
      "4                  Crime|Mystery|Thriller  \n",
      "Archivo combinado guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Especifica el delimitador si es necesario\n",
    "ruta_rating = r'C:\\Users\\jhonc\\Downloads\\rating_id.csv'\n",
    "ruta_movie = r'C:\\Users\\jhonc\\Downloads\\movie_id.csv'\n",
    "\n",
    "# Leer el archivo de películas con un delimitador adecuado (si es necesario)\n",
    "movies = pd.read_csv(ruta_movie, sep=';')  # Ajusta el delimitador si es necesario\n",
    "\n",
    "# Leer el archivo de valoraciones (ratings)\n",
    "ratings = pd.read_csv(ruta_rating, sep=';')  # Ajusta el delimitador si es necesario\n",
    "\n",
    "# Unir los dos dataframes por la columna 'movieId'\n",
    "merged_data = pd.merge(ratings, movies, on='movieId', how='inner')\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(merged_data.head())\n",
    "\n",
    "# Si tienes una columna 'timestamp', convierte la fecha si es necesario\n",
    "if 'timestamp' in merged_data.columns:\n",
    "    # Convertir la columna 'timestamp' a tipo datetime sin necesidad de 'unit'\n",
    "    merged_data['timestamp'] = pd.to_datetime(merged_data['timestamp'], errors='coerce')\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "merged_data.to_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\movies_with_ratings.csv', index=False)\n",
    "\n",
    "# O guardarlo en formato JSON (opcional)\n",
    "# merged_data.to_json(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\movies_with_ratings.json', orient='records', lines=True)\n",
    "\n",
    "print(\"Archivo combinado guardado exitosamente.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959e92dc-3ca6-4195-8ee9-e00df5bf1fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en jugadores: Index(['PLAYER_NAME', 'TEAM_ID', 'PLAYER_ID', 'SEASON'], dtype='object')\n",
      "Columnas en game: Index(['GAME_ID', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_CITY', 'PLAYER_ID',\n",
      "       'PLAYER_NAME', 'NICKNAME', 'START_POSITION', 'COMMENT', 'MIN', 'FGM',\n",
      "       'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT',\n",
      "       'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS',\n",
      "       'PLUS_MINUS'],\n",
      "      dtype='object')\n",
      "Archivo combinado guardado exitosamente en: C:\\Users\\jhonc\\OneDrive\\Desktop\\game_with_jugadores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Rutas de los archivos CSV\n",
    "ruta_jugadores = r'C:\\Users\\jhonc\\Downloads\\players.csv'\n",
    "ruta_game = r'C:\\Users\\jhonc\\Downloads\\gamesdetalles.csv'\n",
    "\n",
    "# Leer archivos CSV con detección automática del delimitador\n",
    "jugadores = pd.read_csv(ruta_jugadores, sep=None, engine='python')\n",
    "game = pd.read_csv(ruta_game, sep=None, engine='python')\n",
    "\n",
    "# Verificar nombres de columnas\n",
    "print(\"Columnas en jugadores:\", jugadores.columns)\n",
    "print(\"Columnas en game:\", game.columns)\n",
    "\n",
    "# Asegurar que la clave de unión existe en ambos dataframes\n",
    "clave_union = 'PLAYER_ID'  # Ajusta si el nombre no coincide exactamente\n",
    "if clave_union not in jugadores.columns or clave_union not in game.columns:\n",
    "    raise ValueError(f\"La columna '{clave_union}' no se encuentra en ambos archivos.\")\n",
    "\n",
    "# Unir los dos dataframes por la columna común\n",
    "merged_data = pd.merge(jugadores, game, on=clave_union, how='inner')\n",
    "\n",
    "# Verificar si hay una columna timestamp y convertirla\n",
    "if 'timestamp' in merged_data.columns:\n",
    "    merged_data['timestamp'] = pd.to_datetime(merged_data['timestamp'], errors='coerce')\n",
    "\n",
    "# Guardar el archivo combinado\n",
    "output_path = r'C:\\Users\\jhonc\\OneDrive\\Desktop\\game_with_jugadores.csv'\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Archivo combinado guardado exitosamente en:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95c73ff-70ea-4a52-ac0b-8f6cf402fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhonc\\AppData\\Local\\Temp\\ipykernel_9420\\2154752369.py:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\proyecto_git_analisis\\views_movie.csv', sep=';', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo CSV se ha filtrado y guardado con las fechas desde 1996-01-01 hasta la fecha actual.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV con el delimitador correcto\n",
    "df = pd.read_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\proyecto_git_analisis\\views_movie.csv', sep=';', on_bad_lines='skip')\n",
    "\n",
    "# Convertir la columna 'timestamp' a datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "# Filtrar filas con fechas desde el año 2000 hasta la fecha actual\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.to_datetime('today')\n",
    "\n",
    "df_filtered = df[(df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)]\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_filtered = df_filtered.drop_duplicates()\n",
    "\n",
    "# Guardar el DataFrame filtrado y reducido en un archivo CSV\n",
    "df_filtered.to_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\proyecto_git_analisis\\views_movie_96-2015.csv', index=False)\n",
    "\n",
    "# Imprimir un mensaje al finalizar\n",
    "print(f\"El archivo CSV se ha filtrado y guardado con las fechas desde {start_date} hasta la fecha actual.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d582a-4937-4699-bf41-cc4229d3c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "file_path = r'C:\\Users\\jhonc\\Downloads\\registros_api.csv'\n",
    "\n",
    "# Verificar si el archivo existe antes de intentar cargarlo\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"El archivo en la ruta especificada existe: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Cargar el archivo CSV, ignorando líneas con errores\n",
    "        df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "        print(\"Archivo cargado con éxito.\")\n",
    "        \n",
    "        # Eliminar duplicados en todo el DataFrame\n",
    "        df_sin_duplicados = df.drop_duplicates()\n",
    "        print(\"Duplicados eliminados.\")\n",
    "\n",
    "        # Eliminar filas con valores NaN\n",
    "        df_sin_nan = df_sin_duplicados.dropna()\n",
    "        print(\"Filas con valores NaN eliminadas.\")\n",
    "\n",
    "        # Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "        cleaned_file_path = r'C:\\Users\\jhonc\\Downloads\\registros_api_limpios.csv'\n",
    "        df_sin_nan.to_csv(cleaned_file_path, index=False)\n",
    "        print(f\"Datos limpios guardados en {cleaned_file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar o limpiar el archivo CSV: {e}\")\n",
    "else:\n",
    "    print(f\"El archivo en la ruta especificada no existe: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfe61e7-4924-4c0c-a8e0-d7cdebbe6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar duyplicados \n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV, ignorando líneas con errores\n",
    "df = pd.read_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\views_movies.csv', on_bad_lines='skip')\n",
    "\n",
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Guardar el archivo CSV reducido\n",
    "df.to_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\proyecto_git_analisis\\views_movies_comprimido.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93ab772-a109-4cbb-9c23-7b144343e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'userId' no se encontró en el DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhonc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo CSV se ha dividido en 4 parte(s).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo CSV, ignorando líneas con errores\n",
    "df = pd.read_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\views_movies.csv', on_bad_lines='skip')\n",
    "\n",
    "# Verificar si la columna 'userId' existe y eliminarla\n",
    "if 'userId' in df.columns:\n",
    "    df = df.drop(columns=['userId'])\n",
    "else:\n",
    "    print(\"La columna 'userId' no se encontró en el DataFrame.\")\n",
    "\n",
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Calcular el tamaño del DataFrame en bytes\n",
    "total_size = df.memory_usage(deep=True).sum()\n",
    "\n",
    "# Dividir el DataFrame en partes si el tamaño es mayor de 24MB\n",
    "part_size = 24 * 1024 * 1024  # 24MB en bytes\n",
    "num_parts = -(-total_size // part_size)  # Redondeo hacia arriba\n",
    "\n",
    "# Guardar el archivo CSV reducido y dividirlo en partes si es necesario\n",
    "if num_parts > 1:\n",
    "    for i, chunk in enumerate(np.array_split(df, num_parts)):\n",
    "        part_filename = f'C:\\\\Users\\\\jhonc\\\\OneDrive\\\\Desktop\\\\proyecto_git_analisis\\\\views_movies_comprimido_parte{i+1}.csv'\n",
    "        chunk.to_csv(part_filename, index=False)\n",
    "else:\n",
    "    df.to_csv(r'C:\\Users\\jhonc\\OneDrive\\Desktop\\proyecto_git_analisis\\views_movies_comprimido.csv', index=False)\n",
    "\n",
    "# Imprimir información sobre el archivo resultante\n",
    "print(f\"El archivo CSV se ha dividido en {num_parts} parte(s).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4baa39-6590-4b96-bd0f-ae4877e081c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de partes\n",
    "part_size = 24 * 1024 * 1024  # 24MB en bytes\n",
    "total_size = df.memory_usage(deep=True).sum()\n",
    "num_parts = -(-total_size // part_size)  # Redondeo hacia arriba\n",
    "\n",
    "# Dividir el DataFrame en partes\n",
    "for i, chunk in enumerate(np.array_split(df, num_parts)):\n",
    "    part_filename = f'C:\\\\Users\\\\jhonc\\\\OneDrive\\\\Desktop\\\\proyecto_git_analisis\\\\views_movies_comprimido_parte{i+1}.csv'\n",
    "    chunk.to_csv(part_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
